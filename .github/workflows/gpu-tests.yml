name: GPU Tests

on:
  workflow_dispatch:
    inputs:
      instance_type:
        description: 'EC2 instance type'
        required: false
        type: choice
        default: 'g6.2xlarge'
        options:
          - g5.xlarge    #  4 vCPUs, 16GB RAM, A10G GPU, ≈$1.11/hr
          - g5.2xlarge   #  8 vCPUs, 32GB RAM, A10G GPU, ≈$1.33/hr
          - g5.4xlarge   # 16 vCPUs, 64GB RAM, A10G GPU, ≈$1.79/hr
          - g6.xlarge    #  4 vCPUs, 16GB RAM,   L4 GPU, ≈$0.89/hr
          - g6.2xlarge   #  8 vCPUs, 32GB RAM,   L4 GPU, ≈$1.08/hr
          - g6.4xlarge   # 16 vCPUs, 64GB RAM,   L4 GPU, ≈$1.46/hr
  pull_request:
    paths:
      - 'cubed/backend_array_api.py'
      - 'cubed/storage/virtual.py'
      - 'cubed/tests/**'
      - '.github/workflows/gpu-tests.yml'
      - 'pyproject.toml'
  schedule:
    # Run weekly on Mondays at 03:00 UTC
    - cron: "0 3 * * 1"

permissions:
  id-token: write
  contents: read

jobs:
  ec2:
    name: Start EC2 runner
    uses: Open-Athena/ec2-gha/.github/workflows/runner.yml@v2
    with:
      ec2_instance_type: ${{ inputs.instance_type || 'g6.2xlarge' }}
      ec2_image_id: ami-0aee7b90d684e107d  # Deep Learning OSS Nvidia Driver AMI GPU PyTorch 2.4.1 (Ubuntu 22.04) 20250623
    secrets:
      GH_SA_TOKEN: ${{ secrets.GH_SA_TOKEN }}

  gpu-test-cupy:
    name: GPU Tests (CuPy)
    needs: ec2
    runs-on: ${{ needs.ec2.outputs.id }}
    steps:
      - name: Checkout source
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check GPU
        run: nvidia-smi

      - name: Setup Python environment
        run: |
          # Use the DLAMI's pre-installed PyTorch conda environment
          echo "/opt/conda/envs/pytorch/bin" >> $GITHUB_PATH
          echo "CONDA_DEFAULT_ENV=pytorch" >> $GITHUB_ENV

      - name: Verify Python
        run: python --version

      - name: Setup Graphviz
        run: |
          sudo apt-get update
          sudo apt-get install -y graphviz

      - name: Install CuPy
        run: |
          INSTANCE_TYPE="${{ inputs.instance_type || 'g6.2xlarge' }}"
          
          # Install appropriate CuPy version based on CUDA version
          # The DLAMI typically comes with CUDA 12.x
          pip install cupy-cuda12x

      - name: Install cubed with test dependencies
        run: |
          pip install -e .[test]
          # Install array-api-compat for CuPy support
          pip install array-api-compat

      - name: Verify CuPy installation
        run: |
          python -c "import cupy; print(f'CuPy version: {cupy.__version__}'); print(cupy.show_config())"

      - name: Run tests with CuPy backend
        env:
          CUBED_BACKEND_ARRAY_API_MODULE: "array_api_compat.cupy"
          ZARR_BUFFER: "zarr.buffer.gpu.Buffer"
          ZARR_NDBUFFER: "zarr.buffer.gpu.NDBuffer"
          CUDA_VISIBLE_DEVICES: "0"
        run: |
          # Run tests excluding those that are known to be incompatible with CuPy
          # Using synchronous executor since processes executor doesn't work with CuPy
          pytest -v cubed/tests/test_array_api.py \
            -k "not broadcast_trick and not object_dtype" \
            --maxfail=10 \
            -x

      - name: Run core tests with CuPy backend
        env:
          CUBED_BACKEND_ARRAY_API_MODULE: "array_api_compat.cupy"
          ZARR_BUFFER: "zarr.buffer.gpu.Buffer"
          ZARR_NDBUFFER: "zarr.buffer.gpu.NDBuffer"
          CUDA_VISIBLE_DEVICES: "0"
        run: |
          # Run a subset of core tests to validate GPU execution
          pytest -v cubed/tests/test_core.py::test_from_array \
            cubed/tests/test_core.py::test_to_zarr \
            cubed/tests/test_core.py::test_map_blocks \
            --maxfail=5

  gpu-test-jax:
    name: GPU Tests (JAX)
    needs: ec2
    runs-on: ${{ needs.ec2.outputs.id }}
    steps:
      - name: Checkout source
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check GPU
        run: nvidia-smi

      - name: Setup Python environment
        run: |
          # Use the DLAMI's pre-installed PyTorch conda environment
          echo "/opt/conda/envs/pytorch/bin" >> $GITHUB_PATH
          echo "CONDA_DEFAULT_ENV=pytorch" >> $GITHUB_ENV

      - name: Verify Python
        run: python --version

      - name: Setup Graphviz
        run: |
          sudo apt-get update
          sudo apt-get install -y graphviz

      - name: Install JAX with CUDA support
        run: |
          # Install JAX with CUDA 12 support
          pip install --upgrade "jax[cuda12]"

      - name: Install cubed with test dependencies
        run: |
          pip install -e .[test]
          # Remove lithops if installed to avoid test conflicts
          pip uninstall -y lithops || true

      - name: Verify JAX GPU support
        run: |
          python -c "import jax; print(f'JAX version: {jax.__version__}'); print(f'GPU devices: {jax.devices()}')"

      - name: Run tests with JAX backend
        env:
          CUBED_BACKEND_ARRAY_API_MODULE: "jax.numpy"
          JAX_ENABLE_X64: "True"
          CUDA_VISIBLE_DEVICES: "0"
        run: |
          # Run tests excluding those that don't work on JAX
          pytest -v cubed/tests/test_array_api.py \
            -k "not broadcast_trick and not object_dtype" \
            --maxfail=10 \
            -x

      - name: Run JAX-specific array tests
        env:
          CUBED_BACKEND_ARRAY_API_MODULE: "jax.numpy"
          JAX_ENABLE_X64: "True"
          CUDA_VISIBLE_DEVICES: "0"
        run: |
          # Run core functionality tests with JAX
          pytest -v cubed/tests/test_core.py::test_from_array \
            cubed/tests/test_core.py::test_compute \
            cubed/tests/test_indexing.py \
            --maxfail=5

  gpu-benchmark:
    name: GPU Performance Benchmark
    needs: ec2
    runs-on: ${{ needs.ec2.outputs.id }}
    steps:
      - name: Checkout source
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check GPU
        run: nvidia-smi

      - name: Setup Python environment
        run: |
          # Use the DLAMI's pre-installed PyTorch conda environment
          echo "/opt/conda/envs/pytorch/bin" >> $GITHUB_PATH
          echo "CONDA_DEFAULT_ENV=pytorch" >> $GITHUB_ENV

      - name: Install dependencies
        run: |
          pip install -e .[test]
          pip install cupy-cuda12x
          pip install "jax[cuda12]"
          pip install array-api-compat
          pip install pandas matplotlib

      - name: Run performance comparison
        run: |
          cat > benchmark_gpu.py << 'EOF'
          import time
          import numpy as np
          import cubed.array_api as xp
          import cubed
          import os
          from contextlib import contextmanager
          
          @contextmanager
          def timer(name):
              start = time.time()
              yield
              end = time.time()
              print(f"{name}: {end - start:.2f} seconds")
          
          def benchmark_backend(backend_name, backend_module, buffer_settings=None):
              print(f"\n{'='*50}")
              print(f"Testing with {backend_name}")
              print('='*50)
              
              # Set backend
              os.environ["CUBED_BACKEND_ARRAY_API_MODULE"] = backend_module
              
              # Set GPU buffer settings if provided
              if buffer_settings:
                  for key, value in buffer_settings.items():
                      os.environ[key] = value
              
              # Reload module to pick up new settings
              import importlib
              importlib.reload(cubed.backend_array_api)
              
              # Create spec with temporary directory
              spec = cubed.Spec("/tmp/cubed_bench", allowed_mem="8GB")
              
              # Test 1: Array creation and computation
              with timer(f"{backend_name} - Create and sum 100M element array"):
                  a = xp.arange(100_000_000, chunks=(10_000_000,), spec=spec)
                  result = xp.sum(a).compute()
                  print(f"  Result: {result}")
              
              # Test 2: Matrix multiplication
              size = 5000
              with timer(f"{backend_name} - Matrix multiplication ({size}x{size})"):
                  a = xp.ones((size, size), chunks=(1000, 1000), spec=spec)
                  b = xp.ones((size, size), chunks=(1000, 1000), spec=spec)
                  c = xp.matmul(a, b)
                  result = c[0, 0].compute()
                  print(f"  Result [0,0]: {result}")
              
              # Test 3: Reduction operations
              with timer(f"{backend_name} - Reductions on 50M elements"):
                  a = xp.arange(50_000_000, chunks=(5_000_000,), spec=spec)
                  mean_val = xp.mean(a).compute()
                  max_val = xp.max(a).compute()
                  print(f"  Mean: {mean_val}, Max: {max_val}")
          
          # Run benchmarks
          print("GPU Performance Benchmark for Cubed")
          
          # CPU baseline with NumPy
          benchmark_backend("NumPy (CPU)", "numpy")
          
          # GPU with CuPy
          try:
              import cupy
              benchmark_backend(
                  "CuPy (GPU)",
                  "array_api_compat.cupy",
                  {
                      "ZARR_BUFFER": "zarr.buffer.gpu.Buffer",
                      "ZARR_NDBUFFER": "zarr.buffer.gpu.NDBuffer"
                  }
              )
          except ImportError:
              print("CuPy not available, skipping")
          
          # GPU with JAX
          try:
              import jax
              benchmark_backend("JAX (GPU)", "jax.numpy")
          except ImportError:
              print("JAX not available, skipping")
          EOF
          
          python benchmark_gpu.py

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: gpu-benchmark-results
          path: |
            benchmark_*.txt
            *.png
